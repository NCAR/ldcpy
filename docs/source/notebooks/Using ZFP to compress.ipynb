{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ZFP to compress data\n",
    "\n",
    "## Importing the required libraries/packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to import the following libraries and/or packages:\n",
    "- ``numpy``,\n",
    "- ``xarray``,\n",
    "- ``math``\n",
    "- ``zfpy`` which is a python wrapper for ZFP algorithm,\n",
    "- ``getsizeof`` to check the array sizes in bytes.\n",
    "\n",
    "For the full documentation of ``zfpy`` you could click [here](https://zfp.readthedocs.io/en/release0.5.5/python.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import math\n",
    "import zfpy\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will provide a separate instruction on how to install ``zfpy``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing a numpy array\n",
    "First we try to compress some numpy array of type ``integer`` and ``double``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(int_arr): <class 'numpy.ndarray'>\n",
      "int_array.dtype: int64\n",
      "number of elements: 100\n",
      "int_array.nbytes: 800\n",
      "size in memory: 896\n"
     ]
    }
   ],
   "source": [
    "int_arr = np.arange(0,100,dtype='int64')\n",
    "print(f\"type(int_arr): {type(int_arr)}\")\n",
    "print(f\"int_array.dtype: {int_arr.dtype}\")\n",
    "print(f\"number of elements: {int_arr.size}\")\n",
    "print(f\"int_array.nbytes: {int_arr.nbytes}\")\n",
    "print(f\"size in memory: {getsizeof(int_arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our integer ``ndarray`` which has 100 ``int64`` elements, i.e. 8B per elements, consumes 800B for the data portion. The total size in memory (visible to Python) is 896B.\n",
    "\n",
    "Now let's compress it using ``zfpy``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(int_arr_compressed): <class 'bytes'>\n",
      "number of elements: 264\n",
      "size in memory: 297\n"
     ]
    }
   ],
   "source": [
    "int_arr_compressed = zfpy.compress_numpy(int_arr)\n",
    "print(f\"type(int_arr_compressed): {type(int_arr_compressed)}\")\n",
    "print(f\"number of elements: {len(int_arr_compressed)}\")\n",
    "print(f\"size in memory: {getsizeof(int_arr_compressed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed version has 264 elements of type bytes, but the overall memory consumption is 264B.\n",
    "\n",
    "if we donot provide any other parameters/arguments, the lossless compression is used. This means that once decompressed, we should get the exact data. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min difference: 0\n",
      "max difference: 0\n"
     ]
    }
   ],
   "source": [
    "int_arr_decompressed = zfpy.decompress_numpy(int_arr_compressed)\n",
    "print(f\"min difference: {(int_arr_decompressed- int_arr).min()}\")\n",
    "print(f\"max difference: {(int_arr_decompressed- int_arr).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, now you know how to decompress data using ``zfpy`` as well.\n",
    "\n",
    "Let's repeat the same procedure for a ``double`` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(double_arr): <class 'numpy.ndarray'>\n",
      "double_array.dtype: float64\n",
      "number of elements: 100\n",
      "double_array.nbytes: 800\n",
      "size in memory: 896\n"
     ]
    }
   ],
   "source": [
    "double_arr = np.arange(0,100, dtype='double')\n",
    "print(f\"type(double_arr): {type(double_arr)}\")\n",
    "print(f\"double_array.dtype: {double_arr.dtype}\")\n",
    "print(f\"number of elements: {double_arr.size}\")\n",
    "print(f\"double_array.nbytes: {double_arr.nbytes}\")\n",
    "print(f\"size in memory: {getsizeof(double_arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compressing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(double_arr_compressed): <class 'bytes'>\n",
      "number of elements: 128\n",
      "size in memory: 161\n"
     ]
    }
   ],
   "source": [
    "double_arr_compressed = zfpy.compress_numpy(double_arr)\n",
    "print(f\"type(double_arr_compressed): {type(double_arr_compressed)}\")\n",
    "print(f\"number of elements: {len(double_arr_compressed)}\")\n",
    "print(f\"size in memory: {getsizeof(double_arr_compressed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both ``int_arr`` and ``double_arr`` are storing same numbers (but in different data type) it appears that the ``double`` is compressed better. Let's decompress and make sure it was lossless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min difference: 0.0\n",
      "max difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "double_arr_decompressed = zfpy.decompress_numpy(double_arr_compressed)\n",
    "print(f\"min difference: {(double_arr_decompressed- double_arr).min()}\")\n",
    "print(f\"max difference: {(double_arr_decompressed- double_arr).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looking good so far.\n",
    "\n",
    "Now let's try a real data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing real data set\n",
    "\n",
    "Now let's open some real data and check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(TS): <class 'numpy.ndarray'>\n",
      "TS.dtype: float32\n",
      "number of elements: 5529600\n",
      "TS.nbytes: 22118400B or 21.09MB\n",
      "size in memory: 128\n"
     ]
    }
   ],
   "source": [
    "ds =xr.open_dataset('../../../data/cam-fv/orig.TS.100days.nc')\n",
    "TS = ds.TS.values\n",
    "print(f\"type(TS): {type(TS)}\")\n",
    "print(f\"TS.dtype: {TS.dtype}\")\n",
    "print(f\"number of elements: {TS.size}\")\n",
    "print((f\"TS.nbytes: {TS.nbytes}B or %.2fMB\") % (TS.nbytes/1024/1024) )\n",
    "\n",
    "print(f\"size in memory: {getsizeof(TS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compressing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(TS_compressed): <class 'bytes'>\n",
      "number of elements: 12464768 (11.89MB)\n",
      "size in memory: 12464801\n"
     ]
    }
   ],
   "source": [
    "TS_compressed = zfpy.compress_numpy(TS)\n",
    "print(f\"type(TS_compressed): {type(TS_compressed)}\")\n",
    "print( (f\"number of elements: {len(TS_compressed)} (%.2fMB)\") % (len(TS_compressed)/1024/1024) )\n",
    "print(f\"size in memory: {getsizeof(TS_compressed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the compression ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression ratio: 56.35%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"compression ratio: %0.2f%%\\n\" % (len(TS_compressed)/TS.nbytes*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's decompress and make sure we are getting the original input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min difference: 0.0\n",
      "max difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "TS_decompressed = zfpy.decompress_numpy(TS_compressed)\n",
    "print(f\"min difference: {(TS_decompressed- TS).min()}\")\n",
    "print(f\"max difference: {(TS_decompressed- TS).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All is good. Now let's try different tolerance and see how the error and compression ratio changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying tolerance = 10^p; 0 <= p <= 5. Please wait ......\n",
      "\n",
      "\n",
      " Tolerance     CR               RMSE (min, max err)\n",
      "-----------------------------------------------------------\n",
      " -1.00000     56.35    0.00000000 ( 0.00000000, 0.00000000)\n",
      "  0.00001     58.65    0.00000028 (-0.00001526, 0.00000000)\n",
      "  0.00010     54.91    0.00000135 (-0.00003052, 0.00001526)\n",
      "  0.00100     42.41    0.00004350 (-0.00027466, 0.00024414)\n",
      "  0.01000     33.03    0.00034111 (-0.00196838, 0.00222778)\n",
      "  0.10000     23.71    0.00266330 (-0.01647949, 0.01643372)\n",
      "  1.00000     12.70    0.03611637 (-0.27249146, 0.26344299)\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tolerance = -1\n",
    "tmpTS_compressed = zfpy.compress_numpy(TS, tolerance=tolerance)\n",
    "compression_ratio = (len(tmpTS_compressed)/TS.nbytes*100)\n",
    "tmpTS_decompressed = zfpy.decompress_numpy(tmpTS_compressed)\n",
    "rmse = np.sqrt(np.power(tmpTS_decompressed - TS, 2).mean())\n",
    "min_err = (tmpTS_decompressed - TS).min()\n",
    "max_err = (tmpTS_decompressed - TS).max()\n",
    "results = [\n",
    "    (tolerance, compression_ratio, rmse, min_err, max_err)\n",
    "]\n",
    "zfpy.compress_numpy(TS, tolerance=-1)\n",
    "max_p = 5\n",
    "print(f\"Trying tolerance = 10^p; 0 <= p <= {max_p}. Please wait \",end=\"\")\n",
    "for p in range(-max_p, 1):\n",
    "    print(\".\", end='')\n",
    "    tolerance = math.pow(10,p)\n",
    "    tmpTS_compressed = zfpy.compress_numpy(TS, tolerance=tolerance)\n",
    "\n",
    "    compression_ratio = (len(tmpTS_compressed)/TS.nbytes*100)\n",
    "    tmpTS_decompressed = zfpy.decompress_numpy(tmpTS_compressed)\n",
    "    \n",
    "    rmse = np.sqrt(np.power(tmpTS_decompressed - TS, 2).mean())\n",
    "    \n",
    "    min_err = (tmpTS_decompressed - TS).min()\n",
    "    max_err = (tmpTS_decompressed - TS).max()\n",
    "    \n",
    "    results.append( (tolerance, compression_ratio, rmse, min_err, max_err) )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\" Tolerance     CR               RMSE (min, max err)\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "for e in results:\n",
    "    print( (f\"%9.{max_p}f     %5.2f    %.8f (%11.8f,%11.8f)\") % e )\n",
    "print(\"-----------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
